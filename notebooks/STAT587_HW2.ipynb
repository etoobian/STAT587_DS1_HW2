{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2623dba2",
   "metadata": {},
   "source": [
    "# **STAT 587 &mdash; Data Science I** &mdash; Homework 2\n",
    "**Winter 2026**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09857722",
   "metadata": {},
   "source": [
    "## **Imports & Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb29fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "# Ensure output directories exist\n",
    "from src.paths import ensure_dirs, DATA_DIR, FIG_DIR, TAB_DIR\n",
    "\n",
    "ensure_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8155f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from ISLP import load_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68425fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb591c",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad135b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes to LaTex Tables\n",
    "\n",
    "def df_to_tabular_tex(df, *, float_fmt=\"%.4f\", index=True):\n",
    "    \"\"\"Return LaTeX tabular with booktabs formatting.\"\"\"\n",
    "    return df.to_latex(\n",
    "        index=index,\n",
    "        escape=False,\n",
    "        float_format=(lambda x: float_fmt % x) if float_fmt else None,\n",
    "        bold_rows=False,\n",
    "        longtable=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def wrap_table(tabular_tex, *, caption, label):\n",
    "    \"\"\"Wrap a tabular in a standalone LaTeX table environment.\"\"\"\n",
    "    return \"\\n\".join(\n",
    "        [\n",
    "            r\"\\begin{table}[H]\",\n",
    "            r\"\\begin{center}\",\n",
    "            tabular_tex.strip(),\n",
    "            r\"\\end{center}\",\n",
    "            r\"\\vspace{-5pt}\",\n",
    "            rf\"\\caption{{{caption}}}\",\n",
    "            rf\"\\label{{{label}}}\",\n",
    "            r\"\\end{table}\",\n",
    "            \"\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2da0de",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca9716",
   "metadata": {},
   "source": [
    "## **Question 1:** College Data (ISLP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6e01b4",
   "metadata": {},
   "source": [
    "### Data Load, Initial Inspection, Split, Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e24544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "q1_df = load_data(\"College\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42d4a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial EDA summary\n",
    "\n",
    "# Identify categorical vs numeric columns\n",
    "q1_cat_cols = q1_df.select_dtypes(\n",
    "    include=[\"object\", \"category\", \"bool\"]\n",
    ").columns.tolist()\n",
    "q1_num_cols = [c for c in q1_df.columns if c not in q1_cat_cols]\n",
    "\n",
    "# Categorical Variable Inspection\n",
    "q1_cat_levels = {}\n",
    "for col in q1_cat_cols:\n",
    "    levels = sorted(q1_df[col].astype(str).unique().tolist())\n",
    "    q1_cat_levels[col] = levels\n",
    "\n",
    "q1_cat_levels_str = (\n",
    "    \"; \".join([f\"{col}:\" + \"|\".join(levels) for col, levels in q1_cat_levels.items()])\n",
    "    if q1_cat_levels\n",
    "    else \"(none)\"\n",
    ")\n",
    "\n",
    "# Numeric Variable Inspection\n",
    "q1_num_summary = q1_df[q1_num_cols].describe().T\n",
    "\n",
    "q1_num_ranges_str = (\n",
    "    \"; \".join(\n",
    "        [\n",
    "            f\"{col}[{q1_num_summary.loc[col, 'min']:.0f},{q1_num_summary.loc[col, 'max']:.0f}]\"\n",
    "            for col in q1_num_summary.index\n",
    "        ]\n",
    "    )\n",
    "    if len(q1_num_cols) > 0\n",
    "    else \"(none)\"\n",
    ")\n",
    "\n",
    "# Target variable inspection\n",
    "q1_apps_summary = q1_df[\"Apps\"].describe()\n",
    "\n",
    "q1_apps_str = (\n",
    "    f\"min={q1_apps_summary['min']:.0f}, \"\n",
    "    f\"q1={q1_apps_summary['25%']:.0f}, \"\n",
    "    f\"median={q1_apps_summary['50%']:.0f}, \"\n",
    "    f\"mean={q1_apps_summary['mean']:.1f}, \"\n",
    "    f\"q3={q1_apps_summary['75%']:.0f}, \"\n",
    "    f\"max={q1_apps_summary['max']:.0f}\"\n",
    ")\n",
    "\n",
    "# Build EDA  Summary table\n",
    "q1_eda_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"item\": [\n",
    "            \"n_rows\",\n",
    "            \"n_cols\",\n",
    "            \"columns\",\n",
    "            \"categorical_cols\",\n",
    "            \"categorical_levels\",\n",
    "            \"numeric_cols\",\n",
    "            \"numeric_ranges_minmax\",\n",
    "            \"target\",\n",
    "            \"Apps_summary\",\n",
    "        ],\n",
    "        \"value\": [\n",
    "            q1_df.shape[0],\n",
    "            q1_df.shape[1],\n",
    "            \", \".join(q1_df.columns.astype(str).tolist()),\n",
    "            \", \".join(q1_cat_cols) if q1_cat_cols else \"(none)\",\n",
    "            q1_cat_levels_str,\n",
    "            \", \".join(q1_num_cols),\n",
    "            q1_num_ranges_str,\n",
    "            \"Apps\",\n",
    "            q1_apps_str,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "# q1_eda_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4039b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Checks\n",
    "assert len(q1_df) > 0, \"College dataset is empty.\"\n",
    "assert \"Apps\" in q1_df.columns, \"Target variable 'Apps' not found.\"\n",
    "assert q1_df.isna().sum().sum() == 0, \"Unexpected missing values in College dataset.\"\n",
    "\n",
    "# Categorical checks\n",
    "if \"Private\" in q1_df.columns:\n",
    "    assert set(q1_df[\"Private\"].astype(str).unique()) == {\n",
    "        \"Yes\",\n",
    "        \"No\",\n",
    "    }, \"Unexpected levels in 'Private' variable.\"\n",
    "\n",
    "# Numeric checks\n",
    "assert (\n",
    "    q1_df[q1_num_cols].isna().sum().sum() == 0\n",
    "), \"Missing values in numeric predictors.\"\n",
    "assert all(\n",
    "    pd.api.types.is_numeric_dtype(q1_df[c]) for c in q1_num_cols\n",
    "), \"Non-numeric dtype found in numeric predictors.\"\n",
    "\n",
    "# Target checks\n",
    "assert (q1_df[\"Apps\"] > 0).all(), \"Applications count must be positive.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "n_missing = int(q1_df.isna().sum().sum())\n",
    "assert n_missing == 0, f\"Missing values exist in data: total missing = {n_missing}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41ef4777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (80/20)\n",
    "q1_X = q1_df.drop(columns=[\"Apps\"])\n",
    "q1_y = q1_df[\"Apps\"].to_numpy()\n",
    "\n",
    "q1_X_train, q1_X_test, q1_y_train, q1_y_test = train_test_split(\n",
    "    q1_X, q1_y, test_size=0.2, random_state=SEED\n",
    ")\n",
    "\n",
    "# Checks\n",
    "assert q1_X_train.shape[0] + q1_X_test.shape[0] == q1_df.shape[0]\n",
    "assert q1_y_train.shape[0] + q1_y_test.shape[0] == q1_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3754869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared Preprocessing\n",
    "\n",
    "# Identify columns from predictors only\n",
    "q1_X = q1_df.drop(columns=[\"Apps\"])\n",
    "q1_y = q1_df[\"Apps\"].to_numpy()\n",
    "\n",
    "q1_cat_cols = q1_X.select_dtypes(\n",
    "    include=[\"object\", \"category\", \"bool\"]\n",
    ").columns.tolist()\n",
    "q1_num_cols = [c for c in q1_X.columns if c not in q1_cat_cols]\n",
    "\n",
    "# Preprocess: pass numeric through, one-hot encode categoricals\n",
    "q1_preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", q1_num_cols),\n",
    "        (\"cat\", OneHotEncoder(drop=\"if_binary\", handle_unknown=\"ignore\"), q1_cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47fb0a5",
   "metadata": {},
   "source": [
    "### Q1-Specific Helper Functions and \"Global\" Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665d5f53",
   "metadata": {},
   "source": [
    "### **1(a)** Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "20b358d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Least Squares Linear Model\n",
    "q1a_lm = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", q1_preprocess),\n",
    "        (\"model\", LinearRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "q1a_lm.fit(q1_X_train, q1_y_train)\n",
    "assert hasattr(q1a_lm.named_steps[\"model\"], \"coef_\"), \"Error in lm fit.\"\n",
    "\n",
    "# Test predictions\n",
    "q1a_y_test_pred = q1a_lm.predict(q1_X_test)\n",
    "\n",
    "# Test MSE\n",
    "q1a_test_mse = mean_squared_error(q1_y_test, q1a_y_test_pred)\n",
    "assert q1a_test_mse > 0, \"MSE greater than zero.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd1ca667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Test Error Table (LaTex)\n",
    "q1a_mse_tbl = pd.DataFrame(\n",
    "    {\n",
    "        \"Metric\": [\"Test MSE\"],\n",
    "        \"Value\": [q1a_test_mse],\n",
    "    }\n",
    ")\n",
    "\n",
    "q1a_mse_tex = wrap_table(\n",
    "    df_to_tabular_tex(q1a_mse_tbl, float_fmt=\"%.4f\", index=False),\n",
    "    caption=\"Test-set mean squared error (MSE) for the least squares linear regression model.\",\n",
    "    label=\"tab:q1a-lm-test-mse\",\n",
    ")\n",
    "\n",
    "(TAB_DIR / \"q1a_lm_test_mse.tex\").write_text(q1a_mse_tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce521ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1221.6559986506354)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check from large MSE\n",
    "q1a_test_rmse = np.sqrt(q1a_test_mse)\n",
    "# q1a_test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4adadd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract fitted linear model\n",
    "q1a_lr = q1a_lm.named_steps[\"model\"]\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "q1a_feature_names = q1a_lm.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "\n",
    "# Build coefficient table\n",
    "q1a_coef_tbl = pd.DataFrame(\n",
    "    {\n",
    "        \"Predictor\": [\"Intercept\"] + q1a_feature_names.tolist(),\n",
    "        \"Coefficient\": np.concatenate(([q1a_lr.intercept_], q1a_lr.coef_)),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Sanity check\n",
    "assert q1a_coef_tbl.shape[0] == len(q1a_lr.coef_) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "af3f28d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "826"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Coefficient Table\n",
    "q1a_coef_tbl[\"Predictor\"] = q1a_coef_tbl[\"Predictor\"].str.replace(\n",
    "    \"_\", r\"\\_\", regex=False\n",
    ")\n",
    "\n",
    "q1a_coef_tex = wrap_table(\n",
    "    df_to_tabular_tex(q1a_coef_tbl, float_fmt=\"%.4f\", index=False),\n",
    "    caption=\"Estimated coefficients for the least squares linear regression model predicting number of applications.\",\n",
    "    label=\"tab:q1a-lm-coefficients\",\n",
    ")\n",
    "\n",
    "(TAB_DIR / \"q1a_lm_coefficients.tex\").write_text(q1a_coef_tex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d30ef",
   "metadata": {},
   "source": [
    "### **(b)** Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860808fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3b18db2",
   "metadata": {},
   "source": [
    "### **(c)** Pruning via Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c4bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39da288a",
   "metadata": {},
   "source": [
    "### **(d)** Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2618dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dabe9af",
   "metadata": {},
   "source": [
    "### **(e)** Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec5512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b88c0cc9",
   "metadata": {},
   "source": [
    "### **(f)** Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd49529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87c1e906",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12344e1a",
   "metadata": {},
   "source": [
    "## **Question 2:** Business School Admissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0a567f",
   "metadata": {},
   "source": [
    "### Data Load, Initial Inspection, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dff701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "q2_df = pd.read_csv(DATA_DIR / \"admission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "982118c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial EDA summary\n",
    "de_levels = sorted(q2_df[\"De\"].astype(str).unique().tolist())\n",
    "group_levels = sorted(q2_df[\"Group\"].unique().tolist())\n",
    "\n",
    "class_counts = q2_df[\"Group\"].value_counts().sort_index()\n",
    "\n",
    "eda_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"item\": [\n",
    "            \"n_rows\",\n",
    "            \"n_cols\",\n",
    "            \"columns\",\n",
    "            \"De_levels\",\n",
    "            \"Group_levels\",\n",
    "            \"Group_counts\",\n",
    "        ],\n",
    "        \"value\": [\n",
    "            q2_df.shape[0],\n",
    "            q2_df.shape[1],\n",
    "            \", \".join(q2_df.columns.astype(str).tolist()),\n",
    "            \", \".join(de_levels),\n",
    "            \", \".join(map(str, group_levels)),\n",
    "            \"; \".join([f\"{k}:{v}\" for k, v in class_counts.items()]),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "# eda_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c18584be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: Verify categorical labels match numeric group coding\n",
    "category_map = {\"admit\": 1, \"notadmit\": 2, \"border\": 3}\n",
    "\n",
    "categories_match = (q2_df[\"De\"].map(category_map) == q2_df[\"Group\"]).all()\n",
    "assert categories_match, \"Mismatch between De labels and Group codes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1bc539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split:\n",
    "## Last 4 observations in each category -> test\n",
    "## Rest of observations -> train\n",
    "\n",
    "q2_test_idx = q2_df.groupby(\"Group\", sort=False).tail(4).index\n",
    "\n",
    "\n",
    "q2_train_df = q2_df.drop(index=q2_test_idx).copy()\n",
    "q2_test_df = q2_df.loc[q2_test_idx].copy()\n",
    "\n",
    "# Features/labels\n",
    "q2_X_train = q2_train_df[[\"GPA\", \"GMAT\"]].to_numpy()\n",
    "q2_y_train = q2_train_df[\"Group\"].to_numpy()\n",
    "\n",
    "q2_X_test = q2_test_df[[\"GPA\", \"GMAT\"]].to_numpy()\n",
    "q2_y_test = q2_test_df[\"Group\"].to_numpy()\n",
    "\n",
    "# Checks\n",
    "assert len(q2_test_df) == 12\n",
    "assert q2_train_df.shape[0] + q2_test_df.shape[0] == q2_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c96b411",
   "metadata": {},
   "source": [
    "### Q2-Specific Helper Functions and \"Global\" Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ea94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function for scatter plots\n",
    "def plot_q2_scatter(df, ax, order, labels, colors, title=None, alpha=0.7):\n",
    "    \"\"\"Scatter plot of GPA vs GMAT colored by admission group.\"\"\"\n",
    "    for g in order:\n",
    "        subset = df[df[\"Group\"] == g]\n",
    "        ax.scatter(\n",
    "            subset[\"GPA\"],\n",
    "            subset[\"GMAT\"],\n",
    "            label=labels[g],\n",
    "            color=colors[g],\n",
    "            alpha=alpha,\n",
    "            edgecolor=\"k\",\n",
    "            s=60,\n",
    "        )\n",
    "    ax.set_xlabel(\"Undergraduate GPA\", fontsize=12, labelpad=10)\n",
    "    ax.set_ylabel(\"GMAT Score\", fontsize=12, labelpad=10)\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=14, fontweight=\"bold\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "# Mesh for plotting\n",
    "def build_gpa_gmat_mesh(df, *, gpa_pad=0.05, gmat_pad=10, n=300):\n",
    "    gpa_min, gpa_max = df[\"GPA\"].min() - gpa_pad, df[\"GPA\"].max() + gpa_pad\n",
    "    gmat_min, gmat_max = df[\"GMAT\"].min() - gmat_pad, df[\"GMAT\"].max() + gmat_pad\n",
    "\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(gpa_min, gpa_max, n),\n",
    "        np.linspace(gmat_min, gmat_max, n),\n",
    "    )\n",
    "\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    return xx, yy, grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e6c8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color/label mapping for groups\n",
    "q2_labels = {1: \"Admit\", 2: \"Not Admit\", 3: \"Border\"}\n",
    "q2_colors = {1: \"tab:blue\", 2: \"tab:orange\", 3: \"tab:green\"}\n",
    "q2_order = [2, 3, 1]\n",
    "\n",
    "# Names in order: Not Admit, Border, Admit\n",
    "q2_group_names = [q2_labels[g] for g in q2_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86a0455",
   "metadata": {},
   "source": [
    "### **2(a)** Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c820d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: GPA vs GMAT, colored by groups\n",
    "fig_scatter, ax_scatter = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "plot_q2_scatter(\n",
    "    df=q2_train_df,\n",
    "    ax=ax_scatter,\n",
    "    order=q2_order,\n",
    "    labels=q2_labels,\n",
    "    colors=q2_colors,\n",
    "    title=\"Training Data: GPA vs GMAT by Admission Group\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "fig_scatter.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "fig_scatter.savefig(FIG_DIR / \"q2_scatter_gpa_gmat.png\", bbox_inches=\"tight\")\n",
    "plt.close(fig_scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08c72905",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_train_df_plot = q2_train_df.copy()\n",
    "q2_train_df_plot[\"GroupOrdered\"] = pd.Categorical(\n",
    "    q2_train_df_plot[\"Group\"].map(q2_labels),\n",
    "    categories=[q2_labels[g] for g in q2_order],\n",
    "    ordered=True,\n",
    ")\n",
    "\n",
    "fig_box, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Boxplot: GPA by Group\n",
    "q2_train_df_plot.boxplot(column=\"GPA\", by=\"GroupOrdered\", ax=axes[0], grid=False)\n",
    "axes[0].set_title(\"GPA by Admission Group\", fontsize=13)\n",
    "axes[0].set_xlabel(\"Group\", fontsize=12, labelpad=10)\n",
    "axes[0].set_ylabel(\"GPA\", fontsize=12, labelpad=10)\n",
    "\n",
    "# Boxplot: GMAT by Group\n",
    "q2_train_df_plot.boxplot(column=\"GMAT\", by=\"GroupOrdered\", ax=axes[1], grid=False)\n",
    "axes[1].set_title(\"GMAT by Admission Group\", fontsize=13)\n",
    "axes[1].set_xlabel(\"Group\", fontsize=12, labelpad=10)\n",
    "axes[1].set_ylabel(\"GMAT Score\", fontsize=12, labelpad=10)\n",
    "\n",
    "fig_box.suptitle(\n",
    "    \"Training Data: Marginal Distributions by Group\", fontsize=16, fontweight=\"bold\"\n",
    ")\n",
    "fig_box.tight_layout()\n",
    "\n",
    "\n",
    "# Save figure\n",
    "fig_box.savefig(FIG_DIR / \"q2_boxplots_gpa_gmat.png\", bbox_inches=\"tight\")\n",
    "plt.close(fig_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad85d72",
   "metadata": {},
   "source": [
    "### **2(b)** LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8591d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LDA on training data\n",
    "q2_lda = LinearDiscriminantAnalysis()\n",
    "q2_lda.fit(q2_X_train, q2_y_train)\n",
    "\n",
    "# Predictions\n",
    "q2_lda_train_pred = q2_lda.predict(q2_X_train)\n",
    "q2_lda_test_pred = q2_lda.predict(q2_X_test)\n",
    "\n",
    "# Sanity checks\n",
    "assert len(q2_lda_train_pred) == len(q2_y_train)\n",
    "assert len(q2_lda_test_pred) == len(q2_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a0ce27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a mesh over predictor space\n",
    "xx, yy, grid = build_gpa_gmat_mesh(q2_train_df)\n",
    "Z = q2_lda.predict(grid).reshape(xx.shape)\n",
    "\n",
    "# Plot decision regions + training points\n",
    "fig_lda, ax_lda = plt.subplots(figsize=(6.5, 5.5))\n",
    "\n",
    "# Decision regions\n",
    "ax_lda.contourf(xx, yy, Z, alpha=0.18)\n",
    "\n",
    "# Decision boundaries\n",
    "ax_lda.contour(xx, yy, Z, levels=[1.5, 2.5], colors=\"k\", linewidths=1)\n",
    "\n",
    "plot_q2_scatter(\n",
    "    df=q2_train_df,\n",
    "    ax=ax_lda,\n",
    "    order=q2_order,\n",
    "    labels=q2_labels,\n",
    "    colors=q2_colors,\n",
    "    title=\"LDA Decision Regions (Training Data)\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "fig_lda.tight_layout()\n",
    "\n",
    "# Save plot artifact\n",
    "fig_lda.savefig(FIG_DIR / \"q2_lda_boundary.png\", bbox_inches=\"tight\")\n",
    "plt.close(fig_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5332cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "# Rows = true class, Columns = predicted class\n",
    "# Order: Not Admit (2), Border (3), Admit (1)\n",
    "q2_lda_cm_train = confusion_matrix(\n",
    "    q2_y_train,\n",
    "    q2_lda_train_pred,\n",
    "    labels=q2_order\n",
    ")\n",
    "\n",
    "q2_lda_cm_test = confusion_matrix(\n",
    "    q2_y_test,\n",
    "    q2_lda_test_pred,\n",
    "    labels=q2_order\n",
    ")\n",
    "\n",
    "# Overall misclassification rates\n",
    "q2_lda_train_err = 1.0 - np.mean(q2_lda_train_pred == q2_y_train)\n",
    "q2_lda_test_err = 1.0 - np.mean(q2_lda_test_pred == q2_y_test)\n",
    "\n",
    "# Sanity checks\n",
    "assert q2_lda_cm_train.shape == (3, 3)\n",
    "assert q2_lda_cm_test.shape == (3, 3)\n",
    "assert 0.0 <= q2_lda_train_err <= 1.0\n",
    "assert 0.0 <= q2_lda_test_err <= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "253053aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1029"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrices as labeled DataFrames\n",
    "q2_lda_cm_train_df = pd.DataFrame(\n",
    "    q2_lda_cm_train, index=q2_group_names, columns=q2_group_names\n",
    ")\n",
    "q2_lda_cm_test_df = pd.DataFrame(\n",
    "    q2_lda_cm_test, index=q2_group_names, columns=q2_group_names\n",
    ")\n",
    "\n",
    "# Error-rate summary\n",
    "q2_lda_metrics_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Misclassification Rate\": [q2_lda_train_err, q2_lda_test_err],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create LaTex tables\n",
    "q2_lda_all_tables_tex = \"\\n\".join(\n",
    "    [\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_lda_cm_train_df, index=True, float_fmt=None),\n",
    "            caption=\"LDA confusion matrix (training data). Rows are true classes and columns are predicted classes.\",\n",
    "            label=\"tab:q2_lda_cm_train\",\n",
    "        ),\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_lda_cm_test_df, index=True, float_fmt=None),\n",
    "            caption=\"LDA confusion matrix (test data). Rows are true classes and columns are predicted classes.\",\n",
    "            label=\"tab:q2_lda_cm_test\",\n",
    "        ),\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_lda_metrics_df, index=False, float_fmt=\"%.4f\"),\n",
    "            caption=\"LDA overall misclassification rates.\",\n",
    "            label=\"tab:q2_lda_error_rates\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Write output\n",
    "(TAB_DIR / \"q2_lda_tables.tex\").write_text(q2_lda_all_tables_tex, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429e5efe",
   "metadata": {},
   "source": [
    "\n",
    "### **2(c)** QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "928fb507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit QDA on training data\n",
    "q2_qda = QuadraticDiscriminantAnalysis()\n",
    "q2_qda.fit(q2_X_train, q2_y_train)\n",
    "\n",
    "# Predictions\n",
    "q2_qda_train_pred = q2_qda.predict(q2_X_train)\n",
    "q2_qda_test_pred  = q2_qda.predict(q2_X_test)\n",
    "\n",
    "# Sanity checks\n",
    "assert len(q2_qda_train_pred) == len(q2_y_train)\n",
    "assert len(q2_qda_test_pred) == len(q2_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ecc5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build mesh over predictor space\n",
    "xx, yy, grid = build_gpa_gmat_mesh(q2_train_df)\n",
    "Z = q2_qda.predict(grid).reshape(xx.shape)\n",
    "\n",
    "# Plot decision regions + training points\n",
    "fig_qda, ax_qda = plt.subplots(figsize=(6.5, 5.5))\n",
    "\n",
    "# Decision regions\n",
    "ax_qda.contourf(xx, yy, Z, alpha=0.18)\n",
    "\n",
    "# Decision boundaries\n",
    "ax_qda.contour(xx, yy, Z, levels=[1.5, 2.5], colors=\"k\", linewidths=1)\n",
    "\n",
    "plot_q2_scatter(\n",
    "    df=q2_train_df,\n",
    "    ax=ax_qda,\n",
    "    order=q2_order,\n",
    "    labels=q2_labels,\n",
    "    colors=q2_colors,\n",
    "    title=\"QDA Decision Regions (Training Data)\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "fig_qda.tight_layout()\n",
    "fig_qda.savefig(FIG_DIR / \"q2_qda_boundary.png\", bbox_inches=\"tight\")\n",
    "plt.close(fig_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2503daf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "# Rows = true class, Columns = predicted class\n",
    "# Order: Not Admit (2), Border (3), Admit (1)\n",
    "q2_qda_cm_train = confusion_matrix(\n",
    "    q2_y_train,\n",
    "    q2_qda_train_pred,\n",
    "    labels=q2_order\n",
    ")\n",
    "\n",
    "q2_qda_cm_test = confusion_matrix(\n",
    "    q2_y_test,\n",
    "    q2_qda_test_pred,\n",
    "    labels=q2_order\n",
    ")\n",
    "\n",
    "# Misclassification rates\n",
    "q2_qda_train_err = 1.0 - np.mean(q2_qda_train_pred == q2_y_train)\n",
    "q2_qda_test_err  = 1.0 - np.mean(q2_qda_test_pred  == q2_y_test)\n",
    "\n",
    "# Sanity checks\n",
    "assert q2_qda_cm_train.shape == (3, 3)\n",
    "assert q2_qda_cm_test.shape  == (3, 3)\n",
    "assert 0.0 <= q2_qda_train_err <= 1.0\n",
    "assert 0.0 <= q2_qda_test_err  <= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2488e0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1029"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrices as labeled DataFrames\n",
    "q2_qda_cm_train_df = pd.DataFrame(\n",
    "    q2_qda_cm_train, index=q2_group_names, columns=q2_group_names\n",
    ")\n",
    "q2_qda_cm_test_df = pd.DataFrame(\n",
    "    q2_qda_cm_test, index=q2_group_names, columns=q2_group_names\n",
    ")\n",
    "\n",
    "# Error-rate summary\n",
    "q2_qda_metrics_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Misclassification Rate\": [q2_qda_train_err, q2_qda_test_err],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create LaTex tables\n",
    "qda_tables_tex = \"\\n\".join(\n",
    "    [\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_qda_cm_train_df, float_fmt=None),\n",
    "            caption=\"QDA confusion matrix (training data). Rows are true classes and columns are predicted classes.\",\n",
    "            label=\"tab:q2_qda_cm_train\",\n",
    "        ),\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_qda_cm_test_df, float_fmt=None),\n",
    "            caption=\"QDA confusion matrix (test data). Rows are true classes and columns are predicted classes.\",\n",
    "            label=\"tab:q2_qda_cm_test\",\n",
    "        ),\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_qda_metrics_df, index=False),\n",
    "            caption=\"QDA overall misclassification rates.\",\n",
    "            label=\"tab:q2_qda_error_rates\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Write output\n",
    "(TAB_DIR / \"q2_qda_tables.tex\").write_text(qda_tables_tex, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4901f473",
   "metadata": {},
   "source": [
    "### **2(d)** KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4246a715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose K by minimizing Test Misclassification Rate\n",
    "\n",
    "# Odd k to Reduce class tie frequencies\n",
    "q2_knn_K_values = list(range(1, 26, 2))\n",
    "q2_knn_test_errors = []\n",
    "\n",
    "for K in q2_knn_K_values:\n",
    "    # Use Pipeline to avoid scaling data leakage and scaling errors\n",
    "    q2_knn = Pipeline(\n",
    "        [(\"scalar\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=K))]\n",
    "    )\n",
    "    q2_knn.fit(q2_X_train, q2_y_train)\n",
    "    q2_test_pred = q2_knn.predict(q2_X_test)\n",
    "\n",
    "    test_err = 1.0 - np.mean(q2_test_pred == q2_y_test)\n",
    "    q2_knn_test_errors.append(test_err)\n",
    "\n",
    "q2_knn_results_df = pd.DataFrame(\n",
    "    {\"K\": q2_knn_K_values, \"test_error_rate\": q2_knn_test_errors}\n",
    ")\n",
    "\n",
    "# Optimal K (on test error ties, use smallest K)\n",
    "q2_knn_results_sorted = q2_knn_results_df.sort_values(\n",
    "    [\"test_error_rate\", \"K\"], ascending=[True, True]\n",
    ")\n",
    "\n",
    "q2_knn_best_row = q2_knn_results_sorted.iloc[0]\n",
    "\n",
    "q2_knn_K_star = int(q2_knn_best_row[\"K\"])\n",
    "q2_knn_test_err_star = float(q2_knn_best_row[\"test_error_rate\"])\n",
    "\n",
    "# Sanity Checks\n",
    "assert q2_knn_K_star in q2_knn_K_values\n",
    "assert 0.0 <= q2_knn_test_err_star <= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3912e433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save K-sweep results to LaTex table\n",
    "q2_knn_results_sorted_rename = q2_knn_results_sorted.rename(\n",
    "    columns={\"test_error_rate\": \"Test Error Rate\"}\n",
    ")\n",
    "\n",
    "q2_knn_sweep_tex = wrap_table(\n",
    "    df_to_tabular_tex(q2_knn_results_sorted_rename, index=False),\n",
    "    caption=\"Sorted KNN test error rate (three-class) for candidate values of $K$.\",\n",
    "    label=\"tab:q2_knn_k_sweep\",\n",
    ")\n",
    "\n",
    "(TAB_DIR / \"q2_knn_k_sweep.tex\").write_text(q2_knn_sweep_tex, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef0716ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit K* model on full 3-class training data\n",
    "q2_knn_star = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"knn\", KNeighborsClassifier(n_neighbors=q2_knn_K_star)),\n",
    "    ]\n",
    ")\n",
    "q2_knn_star.fit(q2_X_train, q2_y_train)\n",
    "\n",
    "# 3-class predictions\n",
    "q2_knn_train_pred3 = q2_knn_star.predict(q2_X_train)\n",
    "q2_knn_test_pred3 = q2_knn_star.predict(q2_X_test)\n",
    "\n",
    "# 3-class confusion matrices (ordered as Not Admit, Border, Admit)\n",
    "q2_knn_cm_train3 = confusion_matrix(q2_y_train, q2_knn_train_pred3, labels=q2_order)\n",
    "q2_knn_cm_test3 = confusion_matrix(q2_y_test, q2_knn_test_pred3, labels=q2_order)\n",
    "\n",
    "# 3-class misclassification rates\n",
    "q2_knn_train_err3 = 1.0 - np.mean(q2_knn_train_pred3 == q2_y_train)\n",
    "q2_knn_test_err3 = 1.0 - np.mean(q2_knn_test_pred3 == q2_y_test)\n",
    "\n",
    "# Sanity Checks\n",
    "assert q2_knn_cm_train3.shape == (3, 3)\n",
    "assert q2_knn_cm_test3.shape == (3, 3)\n",
    "assert 0.0 <= q2_knn_train_err3 <= 1.0\n",
    "assert 0.0 <= q2_knn_test_err3 <= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bd9276b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1057"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrices as labeled DataFrames\n",
    "q2_knn_cm_train3_df = pd.DataFrame(\n",
    "    q2_knn_cm_train3, index=q2_group_names, columns=q2_group_names\n",
    ")\n",
    "q2_knn_cm_test3_df = pd.DataFrame(\n",
    "    q2_knn_cm_test3, index=q2_group_names, columns=q2_group_names\n",
    ")\n",
    "\n",
    "# Error-rate summary\n",
    "q2_knn_err3_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Misclassification Rate\": [q2_knn_train_err3, q2_knn_test_err3],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create LaTex tables\n",
    "q2_knn_tables3_tex = \"\\n\".join(\n",
    "    [\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_knn_cm_train3_df, float_fmt=None),\n",
    "            caption=\"KNN confusion matrix at $K^*$ (training data). Rows are true classes and columns are predicted classes.\",\n",
    "            label=\"tab:q2_knn_cm_train3\",\n",
    "        ),\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_knn_cm_test3_df, float_fmt=None),\n",
    "            caption=\"KNN confusion matrix at $K^*$ (test data). Rows are true classes and columns are predicted classes.\",\n",
    "            label=\"tab:q2_knn_cm_test3\",\n",
    "        ),\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_knn_err3_df, index=False),\n",
    "            caption=\"KNN misclassification rates (three-class) at $K^*$.\",\n",
    "            label=\"tab:q2_knn_err3\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Write output\n",
    "(TAB_DIR / \"q2_knn_3class_tables.tex\").write_text(q2_knn_tables3_tex, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63c301d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass OvR metrics on training data for KNN at K*\n",
    "\n",
    "# Confusion Matrix Totals\n",
    "n = q2_knn_cm_train3.sum()\n",
    "rowsum = q2_knn_cm_train3.sum(axis=1)  # actual totals per class\n",
    "colsum = q2_knn_cm_train3.sum(axis=0)  # predicted totals per class\n",
    "diag = np.diag(q2_knn_cm_train3)\n",
    "\n",
    "# OvR per-class sensitivity and specificity\n",
    "sens = diag / rowsum\n",
    "spec = (n - rowsum - colsum + diag) / (n - rowsum)\n",
    "\n",
    "# Macro averages\n",
    "sens_macro = sens.mean()\n",
    "spec_macro = spec.mean()\n",
    "\n",
    "# Multiclass AUC (OvR macro) using predicted probabilities\n",
    "proba_train = q2_knn_star.predict_proba(q2_X_train)\n",
    "\n",
    "# Align columns to labels [1,2,3] for `roc_auc_score()`\n",
    "proba_df = pd.DataFrame(proba_train, columns=q2_knn_star.named_steps[\"knn\"].classes_)\n",
    "proba_aligned = proba_df[[1, 2, 3]].to_numpy()\n",
    "\n",
    "q2_knn_auc_ovr_macro = roc_auc_score(\n",
    "    q2_y_train, proba_aligned, multi_class=\"ovr\", average=\"macro\"\n",
    ")\n",
    "\n",
    "# Package for table\n",
    "q2_knn_multiclass_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Class\": q2_group_names,\n",
    "        \"Sensitivity (OvR)\": sens,\n",
    "        \"Specificity (OvR)\": spec,\n",
    "    }\n",
    ")\n",
    "\n",
    "q2_knn_multiclass_summary_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Metric\": [\"Macro sensitivity\", \"Macro specificity\", \"AUC (OvR macro)\"],\n",
    "        \"Value\": [sens_macro, spec_macro, q2_knn_auc_ovr_macro],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Sanity checks\n",
    "assert q2_knn_multiclass_df.shape == (3, 3)\n",
    "assert 0.0 <= sens_macro <= 1.0\n",
    "assert 0.0 <= spec_macro <= 1.0\n",
    "assert 0.0 <= q2_knn_auc_ovr_macro <= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "388e2bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_knn_multiclass_tex = \"\\n\".join(\n",
    "    [\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_knn_multiclass_df, float_fmt=\"%.4f\", index=False),\n",
    "            caption=\"KNN multiclass one-vs-rest (OvR) sensitivity and specificity by class (training data) at $K^*$.\",\n",
    "            label=\"tab:q2_knn_ovr_by_class\",\n",
    "        ),\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(\n",
    "                q2_knn_multiclass_summary_df, float_fmt=\"%.4f\", index=False\n",
    "            ),\n",
    "            caption=\"KNN multiclass OvR macro-averaged metrics (training data) at $K^*$.\",\n",
    "            label=\"tab:q2_knn_ovr_summary\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "(TAB_DIR / \"q2_knn_multiclass_metrics.tex\").write_text(\n",
    "    q2_knn_multiclass_tex, encoding=\"utf-8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e8447ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final KNN summary table\n",
    "\n",
    "q2_knn_summary_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Quantity\": [\n",
    "            r\"$K^*$\",\n",
    "            \"Training error rate\",\n",
    "            \"Training sensitivity (OvR, macro)\",\n",
    "            \"Training specificity (OvR, macro)\",\n",
    "            \"Training AUC (OvR, macro)\",\n",
    "            \"Test error rate\",\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            q2_knn_K_star,\n",
    "            q2_knn_train_err3,\n",
    "            sens_macro,\n",
    "            spec_macro,\n",
    "            q2_knn_auc_ovr_macro,\n",
    "            q2_knn_test_err3,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "q2_knn_summary_tex = wrap_table(\n",
    "    df_to_tabular_tex(q2_knn_summary_df, float_fmt=\"%.4f\", index=False),\n",
    "    caption=\"Summary of optimal KNN performance.\",\n",
    "    label=\"tab:q2_knn_summary\",\n",
    ")\n",
    "\n",
    "(TAB_DIR / \"q2_knn_summary.tex\").write_text(q2_knn_summary_tex, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f2a510",
   "metadata": {},
   "source": [
    "### **2(e)** Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb077798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_model_comparison_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\"LDA\", \"QDA\", \"KNN (K=3)\"],\n",
    "        \"Training Error Rate\": [\n",
    "            q2_lda_train_err,\n",
    "            q2_qda_train_err,\n",
    "            q2_knn_train_err3,\n",
    "        ],\n",
    "        \"Test Error Rate\": [\n",
    "            q2_lda_test_err,\n",
    "            q2_qda_test_err,\n",
    "            q2_knn_test_err3,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "q2_model_comparison_tex = wrap_table(\n",
    "    df_to_tabular_tex(q2_model_comparison_df, index=False),\n",
    "    caption=\"Comparison of training and test misclassification rates for LDA, QDA, and KNN.\",\n",
    "    label=\"tab:q2_model_comparison\",\n",
    ")\n",
    "\n",
    "(TAB_DIR / \"q2_model_comparison.tex\").write_text(\n",
    "    q2_model_comparison_tex, encoding=\"utf-8\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
