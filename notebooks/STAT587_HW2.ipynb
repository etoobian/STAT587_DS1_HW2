{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2623dba2",
   "metadata": {},
   "source": [
    "# **STAT 587 &mdash; Data Science I** &mdash; Homework 2\n",
    "**Winter 2026**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09857722",
   "metadata": {},
   "source": [
    "### Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb29fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "# Ensure output directories exist\n",
    "from src.paths import ensure_dirs, DATA_DIR, FIG_DIR, TAB_DIR\n",
    "\n",
    "ensure_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8155f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from ISLP import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68425fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9841a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL OUTPUT CONTROLS\n",
    "\n",
    "VERBOSE = True           # print / display intermediate outputs\n",
    "SAVE_FIGS = True         # write figures to reports/figures\n",
    "SAVE_TABLES = True       # write tables to reports/tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfb591c",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f944bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAG HELPERS\n",
    "\n",
    "\n",
    "# OUTPUT\n",
    "def vprint(*args, **kwargs):\n",
    "    if VERBOSE:\n",
    "        print(*args, **kwargs)\n",
    "\n",
    "\n",
    "# FIGURES\n",
    "def save_fig(fig, filename, *, dpi=300):\n",
    "    \"\"\"Optionally save matplotlib figure to reports/figures and close it.\"\"\"\n",
    "    if SAVE_FIGS:\n",
    "        path = FIG_DIR / filename\n",
    "        fig.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        return path\n",
    "    plt.close(fig)\n",
    "    return None\n",
    "\n",
    "\n",
    "# LaTex TABLES\n",
    "def latex_escape_underscores(s):\n",
    "    \"\"\"Escape underscores for LaTeX.\"\"\"\n",
    "    return str(s).replace(\"_\", r\"\\_\")\n",
    "\n",
    "\n",
    "def escape_df_underscores(df, cols=(\"Predictor\",)):\n",
    "    \"\"\"Escape underscores in specified string columns (returns a copy).\"\"\"\n",
    "    out = df.copy()\n",
    "    for c in cols:\n",
    "        if c in out.columns:\n",
    "            out[c] = out[c].astype(str).apply(latex_escape_underscores)\n",
    "    return out\n",
    "\n",
    "\n",
    "def df_to_tabular_tex(df, *, float_fmt=\"%.4f\", index=True):\n",
    "    \"\"\"Return LaTeX tabular with booktabs formatting.\"\"\"\n",
    "    return df.to_latex(\n",
    "        index=index,\n",
    "        escape=False,\n",
    "        float_format=(lambda x: float_fmt % x) if float_fmt else None,\n",
    "        bold_rows=False,\n",
    "        longtable=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def wrap_table(tabular_tex, *, caption, label):\n",
    "    \"\"\"Wrap a tabular in a standalone LaTeX table environment.\"\"\"\n",
    "    return \"\\n\".join(\n",
    "        [\n",
    "            r\"\\begin{table}[H]\",\n",
    "            r\"\\begin{center}\",\n",
    "            tabular_tex.strip(),\n",
    "            r\"\\end{center}\",\n",
    "            r\"\\vspace{-5pt}\",\n",
    "            rf\"\\caption{{{caption}}}\",\n",
    "            rf\"\\label{{{label}}}\",\n",
    "            r\"\\end{table}\",\n",
    "            \"\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def save_tex_table(\n",
    "    df,\n",
    "    filename,\n",
    "    *,\n",
    "    caption,\n",
    "    label,\n",
    "    float_fmt=\"%.4f\",\n",
    "    index=False,\n",
    "    escape_underscore_cols=None,\n",
    "):\n",
    "    \"\"\"Optionally save a DataFrame as a LaTeX table to reports/tables.\"\"\"\n",
    "    if not SAVE_TABLES:\n",
    "        return None\n",
    "\n",
    "    if escape_underscore_cols:\n",
    "        df = escape_df_underscores(df, cols=escape_underscore_cols)\n",
    "\n",
    "    tex = wrap_table(\n",
    "        df_to_tabular_tex(df, float_fmt=float_fmt, index=index),\n",
    "        caption=caption,\n",
    "        label=label,\n",
    "    )\n",
    "    path = TAB_DIR / filename\n",
    "    path.write_text(tex)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2da0de",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca9716",
   "metadata": {},
   "source": [
    "## **Question 1:** College Data (ISLP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d23d1d",
   "metadata": {},
   "source": [
    "Consider the College data from the ISLP package. Details about the data is described on page 65 of the ISLP textbook for this class (https://islp.readthedocs.io/en/latest/datasets/College.html). We would like to *predict* the *number of applications* received using the other variables. 80% of the data (randomly generated) will be treated as training data. The rest will be the test data.\n",
    "\n",
    "- **Part (a):** Fit a linear model using least squares and report the estimate of the test error.  \n",
    "\n",
    "- **Part (b):** Fit a tree to the data. Summarize the results. Unless the number of terminal nodes is large, display the tree graphically. Report its MSE.  \n",
    "\n",
    "- **Part (c):** Use cross-validation to determine whether pruning is helpful and determine the optimal size for the pruned tree. Compare the pruned and un-pruned trees. Report MSE for the pruned tree. Which predictors seem to be the most important?  \n",
    "\n",
    "- **Part (d):** Use a bagging approach to analyze the data with B = 500 and B = 1000. Compute the MSE. Which predictors seem to be the most important?  \n",
    "\n",
    "- **Part (e):** Repeat (d) with a random forest approach with B = 500 and B = 1000, and $m \\approx p = 3$.  \n",
    "\n",
    "- **Part (f):** Compare the results from the various methods. Which method would you recommend?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f88f5",
   "metadata": {},
   "source": [
    "### Q1-Specific Helper Functions and Shared Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "512b16a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_side_by_side(\n",
    "    feature_names,\n",
    "    importances,\n",
    "    *,\n",
    "    title,\n",
    "    filename_png,\n",
    "    top_k=12,\n",
    "    table_caption=None,\n",
    "    table_label=None,\n",
    "    table_filename_tex=None,\n",
    "    show=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a side-by-side figure:\n",
    "      - Left: horizontal bar plot of top_k importances\n",
    "      - Right: a small table (top_k) rendered into the figure\n",
    "    Optionally also saves a LaTeX table to disk.\n",
    "    \"\"\"\n",
    "    if show is None:\n",
    "        show = VERBOSE\n",
    "\n",
    "    \n",
    "    feature_names = [str(x) for x in feature_names]\n",
    "    importances = np.asarray(importances)\n",
    "\n",
    "    assert len(feature_names) == len(importances)\n",
    "\n",
    "    imp_df = (\n",
    "        pd.DataFrame({\"Predictor\": feature_names, \"Importance\": importances})\n",
    "        .sort_values(\"Importance\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    top_df = imp_df.head(top_k).copy()\n",
    "    top_df_plot = top_df.iloc[::-1].copy()  # reverse for barh so largest at top visually\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(\n",
    "        ncols=2, figsize=(14, 5), gridspec_kw={\"width_ratios\": [2.2, 1.3]}\n",
    "    )\n",
    "\n",
    "    # Bar plot\n",
    "    ax1.barh(top_df_plot[\"Predictor\"], top_df_plot[\"Importance\"])\n",
    "    ax1.set_title(title, fontsize=14, fontweight=\"bold\")\n",
    "    ax1.set_xlabel(\"Importance\", fontsize=12, labelpad=10)\n",
    "    ax1.tick_params(axis=\"y\", labelsize=9)\n",
    "\n",
    "    # Table inside plot \n",
    "    top_tbl = escape_df_underscores(top_df_plot.copy(), cols=(\"Predictor\",))\n",
    "    tbl = ax2.table(\n",
    "        cellText=np.round(top_tbl[[\"Predictor\", \"Importance\"]].values, 4),\n",
    "        colLabels=[\"Predictor\", \"Importance\"],\n",
    "        loc=\"center\",\n",
    "        cellLoc=\"left\",\n",
    "    )\n",
    "    tbl.auto_set_font_size(False)\n",
    "    tbl.set_fontsize(9)\n",
    "    tbl.scale(1, 1.2)\n",
    "\n",
    "    # Optional: save LaTeX table\n",
    "    if table_filename_tex and table_caption and table_label:\n",
    "        top_tbl_tex = escape_df_underscores(top_df.copy(), cols=(\"Predictor\",))\n",
    "        save_tex_table(\n",
    "            top_tbl_tex,\n",
    "            table_filename_tex,\n",
    "            caption=table_caption,\n",
    "            label=table_label,\n",
    "            float_fmt=\"%.4f\",\n",
    "            index=False,\n",
    "            escape_underscore_cols=None,\n",
    "        )\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "    save_fig(fig, filename_png)\n",
    "    \n",
    "    return top_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6e01b4",
   "metadata": {},
   "source": [
    "### Data Load, Initial Inspection, Split, Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e24544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "q1_df = load_data(\"College\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0a3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Checks\n",
    "\n",
    "# Target Column Name\n",
    "q1_y_col = \"Apps\"\n",
    "\n",
    "assert len(q1_df) > 0, \"College dataset is empty.\"\n",
    "assert q1_y_col in q1_df.columns, f\"Target variable '{q1_y_col}' not found.\"\n",
    "\n",
    "n_missing = int(q1_df.isna().sum().sum())\n",
    "assert (\n",
    "    n_missing == 0\n",
    "), f\"Missing values exist in College data: total missing = {n_missing}\"\n",
    "\n",
    "assert (q1_df[q1_y_col] > 0).all(), \"Applications count must be positive.\"\n",
    "\n",
    "# Predictors/target\n",
    "q1_X = q1_df.drop(columns=[q1_y_col])\n",
    "q1_y = q1_df[q1_y_col].to_numpy()\n",
    "\n",
    "# Identify categorical vs numeric columns (predictors)\n",
    "q1_cat_cols = q1_X.select_dtypes(\n",
    "    include=[\"object\", \"category\", \"bool\"]\n",
    ").columns.tolist()\n",
    "q1_num_cols = [c for c in q1_X.columns if c not in q1_cat_cols]\n",
    "\n",
    "assert len(q1_num_cols) + len(q1_cat_cols) == q1_X.shape[1]\n",
    "assert all(pd.api.types.is_numeric_dtype(q1_X[c]) for c in q1_num_cols)\n",
    "\n",
    "# Categorical sanity (specific known field)\n",
    "if \"Private\" in q1_X.columns:\n",
    "    assert set(q1_X[\"Private\"].astype(str).unique()) == {\n",
    "        \"Yes\",\n",
    "        \"No\",\n",
    "    }, \"Unexpected levels in 'Private' variable.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f7c6e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n_rows</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n_cols</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>columns</td>\n",
       "      <td>Private, Apps, Accept, Enroll, Top10perc, Top2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>categorical_cols</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>categorical_levels</td>\n",
       "      <td>Private:No|Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>numeric_cols</td>\n",
       "      <td>Accept, Enroll, Top10perc, Top25perc, F.Underg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>numeric_ranges_minmax</td>\n",
       "      <td>Accept[72,26330]; Enroll[35,6392]; Top10perc[1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>target</td>\n",
       "      <td>Apps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>target_summary</td>\n",
       "      <td>min=81, q1=776, median=1558, mean=3001.6, q3=3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    item                                              value\n",
       "0                 n_rows                                                777\n",
       "1                 n_cols                                                 18\n",
       "2                columns  Private, Apps, Accept, Enroll, Top10perc, Top2...\n",
       "3       categorical_cols                                            Private\n",
       "4     categorical_levels                                     Private:No|Yes\n",
       "5           numeric_cols  Accept, Enroll, Top10perc, Top25perc, F.Underg...\n",
       "6  numeric_ranges_minmax  Accept[72,26330]; Enroll[35,6392]; Top10perc[1...\n",
       "7                 target                                               Apps\n",
       "8         target_summary  min=81, q1=776, median=1558, mean=3001.6, q3=3..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initial EDA summary\n",
    "\n",
    "# Categorical levels\n",
    "q1_cat_levels = {}\n",
    "for col in q1_cat_cols:\n",
    "    q1_cat_levels[col] = sorted(q1_df[col].astype(str).unique().tolist())\n",
    "\n",
    "q1_cat_levels_str = (\n",
    "    \"; \".join([f\"{col}:\" + \"|\".join(levels) for col, levels in q1_cat_levels.items()])\n",
    "    if q1_cat_levels\n",
    "    else \"(none)\"\n",
    ")\n",
    "\n",
    "# Numeric ranges (predictors)\n",
    "q1_num_summary = q1_df[q1_num_cols].describe().T\n",
    "q1_num_ranges_str = (\n",
    "    \"; \".join(\n",
    "        [\n",
    "            f\"{col}[{q1_num_summary.loc[col, 'min']:.0f},{q1_num_summary.loc[col, 'max']:.0f}]\"\n",
    "            for col in q1_num_summary.index\n",
    "        ]\n",
    "    )\n",
    "    if len(q1_num_cols) > 0\n",
    "    else \"(none)\"\n",
    ")\n",
    "\n",
    "# Target summary\n",
    "q1_apps_summary = q1_df[q1_y_col].describe()\n",
    "q1_apps_str = (\n",
    "    f\"min={q1_apps_summary['min']:.0f}, \"\n",
    "    f\"q1={q1_apps_summary['25%']:.0f}, \"\n",
    "    f\"median={q1_apps_summary['50%']:.0f}, \"\n",
    "    f\"mean={q1_apps_summary['mean']:.1f}, \"\n",
    "    f\"q3={q1_apps_summary['75%']:.0f}, \"\n",
    "    f\"max={q1_apps_summary['max']:.0f}\"\n",
    ")\n",
    "\n",
    "q1_eda_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"item\": [\n",
    "            \"n_rows\",\n",
    "            \"n_cols\",\n",
    "            \"columns\",\n",
    "            \"categorical_cols\",\n",
    "            \"categorical_levels\",\n",
    "            \"numeric_cols\",\n",
    "            \"numeric_ranges_minmax\",\n",
    "            \"target\",\n",
    "            \"target_summary\",\n",
    "        ],\n",
    "        \"value\": [\n",
    "            q1_df.shape[0],\n",
    "            q1_df.shape[1],\n",
    "            \", \".join(q1_df.columns.astype(str).tolist()),\n",
    "            \", \".join(q1_cat_cols) if q1_cat_cols else \"(none)\",\n",
    "            q1_cat_levels_str,\n",
    "            \", \".join(q1_num_cols) if q1_num_cols else \"(none)\",\n",
    "            q1_num_ranges_str,\n",
    "            q1_y_col,\n",
    "            q1_apps_str,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "if VERBOSE:\n",
    "    display(q1_eda_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41ef4777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (80/20)\n",
    "q1_X_train, q1_X_test, q1_y_train, q1_y_test = train_test_split(\n",
    "    q1_X, q1_y, test_size=0.2, random_state=SEED\n",
    ")\n",
    "\n",
    "# Checks\n",
    "assert q1_X_train.shape[0] + q1_X_test.shape[0] == q1_df.shape[0]\n",
    "assert q1_y_train.shape[0] + q1_y_test.shape[0] == q1_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3754869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared Preprocessing\n",
    "q1_preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", q1_num_cols),\n",
    "        (\"cat\", OneHotEncoder(drop=\"if_binary\", handle_unknown=\"ignore\"), q1_cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665d5f53",
   "metadata": {},
   "source": [
    "### **1(a)** Least Squares Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20b358d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Least Squares Linear Model\n",
    "q1a_lm = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", q1_preprocess),\n",
    "        (\"model\", LinearRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "q1a_lm.fit(q1_X_train, q1_y_train)\n",
    "assert hasattr(q1a_lm.named_steps[\"model\"], \"coef_\"), \"Error in lm fit.\"\n",
    "\n",
    "# Predictions\n",
    "q1a_y_train_pred = q1a_lm.predict(q1_X_train)\n",
    "q1a_y_test_pred = q1a_lm.predict(q1_X_test)\n",
    "\n",
    "# MSE\n",
    "q1a_train_mse = mean_squared_error(q1_y_train, q1a_y_train_pred)\n",
    "q1a_test_mse = mean_squared_error(q1_y_test, q1a_y_test_pred)\n",
    "\n",
    "assert q1a_train_mse > 0 and q1a_test_mse > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd1ca667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Train/Test Error Table (LaTeX)\n",
    "q1a_mse_tbl = pd.DataFrame(\n",
    "    {\n",
    "        \"Metric\": [\"Train MSE\", \"Test MSE\"],\n",
    "        \"Value\": [q1a_train_mse, q1a_test_mse],\n",
    "    }\n",
    ")\n",
    "\n",
    "_ = save_tex_table(\n",
    "    q1a_mse_tbl,\n",
    "    \"q1a_lm_mse.tex\",\n",
    "    caption=\"Train and test mean squared error (MSE) for the least squares linear regression model.\",\n",
    "    label=\"tab:q1a-lm-mse\",\n",
    "    float_fmt=\"%.4f\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dce521ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 995.0406856856827\n",
      "Test  RMSE:  1221.6559986506354\n"
     ]
    }
   ],
   "source": [
    "# Sanity check from large MSEs\n",
    "q1a_train_rmse = float(np.sqrt(q1a_train_mse))\n",
    "q1a_test_rmse = float(np.sqrt(q1a_test_mse))\n",
    "\n",
    "if VERBOSE:    \n",
    "    print(f\"Train RMSE: {q1a_train_rmse}\")\n",
    "    print(f\"Test  RMSE:  {q1a_test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4adadd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract fitted linear model\n",
    "q1a_lr = q1a_lm.named_steps[\"model\"]\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "q1a_feature_names = q1a_lm.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "\n",
    "# Build coefficient table\n",
    "q1a_coef_tbl = pd.DataFrame(\n",
    "    {\n",
    "        \"Predictor\": [\"Intercept\"] + q1a_feature_names.tolist(),\n",
    "        \"Coefficient\": np.concatenate(([q1a_lr.intercept_], q1a_lr.coef_)),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Sanity check\n",
    "assert q1a_coef_tbl.shape[0] == len(q1a_lr.coef_) + 1\n",
    "\n",
    "# Optionally save Coefficient Table\n",
    "_ = save_tex_table(\n",
    "    q1a_coef_tbl,\n",
    "    \"q1a_lm_coefficients.tex\",\n",
    "    caption=\"Estimated coefficients for the least squares linear regression model predicting number of applications.\",\n",
    "    label=\"tab:q1a-lm-coefficients\",\n",
    "    float_fmt=\"%.4f\",\n",
    "    index=False,\n",
    "    escape_underscore_cols=(\"Predictor\",),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d30ef",
   "metadata": {},
   "source": [
    "### **2(b)** Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860808fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Unpruned Regression Tree\n",
    "q1b_tree = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", q1_preprocess),\n",
    "        (\"model\", DecisionTreeRegressor(random_state=SEED)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "q1b_tree.fit(q1_X_train, q1_y_train)\n",
    "assert hasattr(q1b_tree.named_steps[\"model\"], \"tree_\")\n",
    "\n",
    "# Test predictions\n",
    "q1b_y_test_pred = q1b_tree.predict(q1_X_test)\n",
    "\n",
    "# Test MSE\n",
    "q1b_test_mse = mean_squared_error(q1_y_test, q1b_y_test_pred)\n",
    "assert q1b_test_mse > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d486eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize Tree Size\n",
    "# Tree summary statistics\n",
    "q1b_model = q1b_tree.named_steps[\"model\"]\n",
    "\n",
    "q1b_depth = q1b_model.get_depth()\n",
    "q1b_n_leaves = q1b_model.get_n_leaves()\n",
    "\n",
    "# q1b_depth, q1b_n_leaves\n",
    "# OUTPUT: (21, np.int64(614))\n",
    "# Too big; don't plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b71da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize size in table to justify not plotting\n",
    "q1b_tree_summary_tbl = pd.DataFrame(\n",
    "    {\n",
    "        \"Quantity\": [\"Tree Depth\", \"Number of Terminal Nodes (Leaves)\"],\n",
    "        \"Value\": [q1b_depth, int(q1b_n_leaves)],\n",
    "    }\n",
    ")\n",
    "\n",
    "q1b_tree_summary_tex = wrap_table(\n",
    "    df_to_tabular_tex(q1b_tree_summary_tbl, float_fmt=None, index=False),\n",
    "    caption=\"Summary of the unpruned regression tree fit for predicting applications.\",\n",
    "    label=\"tab:q1b-tree-summary\",\n",
    ")\n",
    "\n",
    "(TAB_DIR / \"q1b_tree_summary.tex\").write_text(q1b_tree_summary_tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1b_mse_tbl = pd.DataFrame(\n",
    "    {\n",
    "        \"Metric\": [\"Test MSE\"],\n",
    "        \"Value\": [q1b_test_mse],\n",
    "    }\n",
    ")\n",
    "\n",
    "q1b_mse_tex = wrap_table(\n",
    "    df_to_tabular_tex(q1b_mse_tbl, float_fmt=\"%.4f\", index=False),\n",
    "    caption=\"Test-set mean squared error (MSE) for the unpruned regression tree.\",\n",
    "    label=\"tab:q1b-tree-test-mse\",\n",
    ")\n",
    "\n",
    "(TAB_DIR / \"q1b_tree_test_mse.tex\").write_text(q1b_mse_tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5941a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check from large MSE\n",
    "q1b_test_rmse = np.sqrt(q1b_test_mse)\n",
    "# q1b_test_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b18db2",
   "metadata": {},
   "source": [
    "### **(c)** Pruned Regression Tree via Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c4bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Cost-Complexity Pruning Path\n",
    "\n",
    "# Fit Unpruned Tree on Training Data\n",
    "q1c_tree_unpruned = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", q1_preprocess),\n",
    "        (\"model\", DecisionTreeRegressor(random_state=SEED)),\n",
    "    ]\n",
    ")\n",
    "q1c_tree_unpruned.fit(q1_X_train, q1_y_train)\n",
    "assert hasattr(q1c_tree_unpruned.named_steps[\"model\"], \"tree_\")\n",
    "\n",
    "# Get Transformed Training Matrix to Compute Pruning Path\n",
    "q1c_X_train_trans = q1c_tree_unpruned.named_steps[\"preprocess\"].transform(q1_X_train)\n",
    "\n",
    "# Sanity check\n",
    "assert q1c_X_train_trans.shape[0] == q1_X_train.shape[0]\n",
    "\n",
    "# Compute Pruning Path for the Fitted (Unpruned) Tree\n",
    "q1c_unpruned_model = q1c_tree_unpruned.named_steps[\"model\"]\n",
    "q1c_path = q1c_unpruned_model.cost_complexity_pruning_path(\n",
    "    q1c_X_train_trans, q1_y_train\n",
    ")\n",
    "\n",
    "q1c_ccp_alphas = q1c_path.ccp_alphas\n",
    "q1c_impurities = q1c_path.impurities\n",
    "\n",
    "assert q1c_ccp_alphas.ndim == 1\n",
    "assert len(q1c_ccp_alphas) == len(q1c_impurities)\n",
    "assert (q1c_ccp_alphas >= 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold CV on Training Data Choose Best alpha\n",
    "q1c_kf = KFold(n_splits=10, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Drop Last alpha (stump)\n",
    "q1c_alphas = q1c_ccp_alphas[:-1]\n",
    "\n",
    "q1c_cv_rows = []\n",
    "\n",
    "for a in q1c_alphas:\n",
    "    q1c_tree = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocess\", q1_preprocess),\n",
    "            (\"model\", DecisionTreeRegressor(random_state=SEED, ccp_alpha=float(a))),\n",
    "        ]\n",
    "    )\n",
    "    # CV MSE (negative in sklearn)\n",
    "    cv_neg_mse = cross_val_score(\n",
    "        q1c_tree,\n",
    "        q1_X_train,\n",
    "        q1_y_train,\n",
    "        cv=q1c_kf,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "    )\n",
    "    q1c_cv_rows.append(\n",
    "        {\n",
    "            \"ccp_alpha\": float(a),\n",
    "            \"cv_mse_mean\": float((-cv_neg_mse).mean()),\n",
    "            \"cv_mse_std\": float((-cv_neg_mse).std(ddof=1)),\n",
    "        }\n",
    "    )\n",
    "\n",
    "q1c_cv_results = pd.DataFrame(q1c_cv_rows)\n",
    "\n",
    "# Choose alpha with Minimum Mean CV MSE\n",
    "q1c_best_row = q1c_cv_results.loc[q1c_cv_results[\"cv_mse_mean\"].idxmin()]\n",
    "q1c_best_alpha = float(q1c_best_row[\"ccp_alpha\"])\n",
    "\n",
    "# Sanity checks\n",
    "assert q1c_cv_results.shape[0] == len(q1c_alphas)\n",
    "assert q1c_best_alpha >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af52e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Results\n",
    "# print(f\"q1c_best_alpha:  {q1c_best_alpha}\")\n",
    "# print(\"\\nq1c_cv_results:\")\n",
    "# q1c_cv_results.sort_values(\"cv_mse_mean\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c2b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV curve figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.plot(\n",
    "    q1c_cv_results[\"ccp_alpha\"],\n",
    "    q1c_cv_results[\"cv_mse_mean\"],\n",
    "    marker=\"o\",\n",
    "    markersize=3,\n",
    "    alpha=0.7,\n",
    "    linestyle=\"-\",\n",
    "    linewidth=1.5,\n",
    ")\n",
    "\n",
    "# Mark Selected alpha\n",
    "ax.axvline(\n",
    "    q1c_best_alpha,\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=r\"Selected $\\alpha$\",\n",
    ")\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(r\"Cost-Complexity Parameter $\\alpha$\", fontsize=12, labelpad=10)\n",
    "ax.set_ylabel(\"Mean CV MSE\", fontsize=12, labelpad=10)\n",
    "ax.set_title(\n",
    "    \"Cross-Validation Curve for Cost-Complexity Pruning\", fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "# Save figure\n",
    "fig.savefig(FIG_DIR / \"q1c_cv_curve.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2705cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Pruned Tree using Best alpha\n",
    "\n",
    "q1c_tree_pruned = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", q1_preprocess),\n",
    "        (\"model\", DecisionTreeRegressor(random_state=SEED, ccp_alpha=q1c_best_alpha)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "q1c_tree_pruned.fit(q1_X_train, q1_y_train)\n",
    "\n",
    "# Sanity check\n",
    "assert hasattr(q1c_tree_pruned.named_steps[\"model\"], \"tree_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece3734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "q1c_y_test_pred = q1c_tree_pruned.predict(q1_X_test)\n",
    "\n",
    "# Test MSE\n",
    "q1c_test_mse = mean_squared_error(q1_y_test, q1c_y_test_pred)\n",
    "assert q1c_test_mse > 0\n",
    "\n",
    "# RMSE sanity check\n",
    "q1c_test_rmse = float(np.sqrt(q1c_test_mse))\n",
    "# q1c_test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d818958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Pruned Depth and Num Leaves\n",
    "q1c_pruned_model = q1c_tree_pruned.named_steps[\"model\"]\n",
    "\n",
    "q1c_pruned_depth = q1c_pruned_model.get_depth()\n",
    "q1c_pruned_n_leaves = q1c_pruned_model.get_n_leaves()\n",
    "\n",
    "assert q1c_pruned_depth >= 0\n",
    "assert q1c_pruned_n_leaves >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f09f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Pruned Test MSE to LaTex table\n",
    "q1c_pruned_mse_tbl = pd.DataFrame({\"Metric\": [\"Test MSE\"], \"Value\": [q1c_test_mse]})\n",
    "\n",
    "q1c_pruned_mse_tex = wrap_table(\n",
    "    df_to_tabular_tex(q1c_pruned_mse_tbl, float_fmt=\"%.4f\", index=False),\n",
    "    caption=\"Test-set mean squared error (MSE) for the pruned regression tree.\",\n",
    "    label=\"tab:q1c-pruned-tree-test-mse\",\n",
    ")\n",
    "\n",
    "(TAB_DIR / \"q1c_pruned_tree_test_mse.tex\").write_text(q1c_pruned_mse_tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3f7b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison Table: Unpruned vs Pruned Trees\n",
    "q1c_tree_comparison_tbl = pd.DataFrame(\n",
    "    {\n",
    "        \"Quantity\": [\n",
    "            \"Tree depth\",\n",
    "            \"Number of terminal nodes (leaves)\",\n",
    "            \"Test MSE\",\n",
    "        ],\n",
    "        \"Unpruned Tree\": [\n",
    "            q1b_depth,\n",
    "            int(q1b_n_leaves),\n",
    "            q1b_test_mse,\n",
    "        ],\n",
    "        \"Pruned Tree\": [\n",
    "            q1c_pruned_depth,\n",
    "            int(q1c_pruned_n_leaves),\n",
    "            q1c_test_mse,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "q1c_tree_comparison_tex = wrap_table(\n",
    "    df_to_tabular_tex(q1c_tree_comparison_tbl, float_fmt=\"%.4f\", index=False),\n",
    "    caption=\"Comparison of unpruned and pruned regression trees for predicting applications.\",\n",
    "    label=\"tab:q1c-tree-comparison\",\n",
    ")\n",
    "\n",
    "(TAB_DIR / \"q1c_tree_comparison.tex\").write_text(q1c_tree_comparison_tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f115f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Importance\n",
    "q1c_feature_names = q1c_tree_pruned.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "q1c_importances = q1c_tree_pruned.named_steps[\"model\"].feature_importances_\n",
    "\n",
    "# Sanity checks\n",
    "assert len(q1c_feature_names) == len(q1c_importances)\n",
    "assert np.isclose(\n",
    "    q1c_importances.sum(), 1.0\n",
    "), f\"Feature importances sum to {q1c_importances.sum():.6f}, expected 1.0\"\n",
    "assert (q1c_importances >= 0).all()\n",
    "\n",
    "q1c_importance_df = pd.DataFrame(\n",
    "    {\"Predictor\": q1c_feature_names, \"Importance\": q1c_importances}\n",
    ").sort_values(\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ad43c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Importance Table to LaTex\n",
    "q1c_importance_full = q1c_importance_df.copy()\n",
    "\n",
    "# Escape underscores for LaTeX\n",
    "q1c_importance_full[\"Predictor\"] = q1c_importance_full[\"Predictor\"].str.replace(\n",
    "    \"_\", r\"\\_\", regex=False\n",
    ")\n",
    "\n",
    "q1c_importance_tex = wrap_table(\n",
    "    df_to_tabular_tex(q1c_importance_full, float_fmt=\"%.4f\", index=False),\n",
    "    caption=\"Variable importances from the pruned regression tree. Predictors with zero importance were not used in any split.\",\n",
    "    label=\"tab:q1c-pruned-tree-importance\",\n",
    ")\n",
    "\n",
    "(TAB_DIR / \"q1c_pruned_tree_importance.tex\").write_text(q1c_importance_tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed44c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruned Tree Plot: Minimal-labels (feature + threshold only)\n",
    "q1c_pruned_model = q1c_tree_pruned.named_steps[\"model\"]\n",
    "q1c_feature_names = q1c_tree_pruned.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(22, 10))\n",
    "\n",
    "plot_tree(\n",
    "    q1c_pruned_model,\n",
    "    feature_names=q1c_feature_names,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    impurity=False,\n",
    "    node_ids=False,\n",
    "    proportion=False,   # no sample proportions\n",
    "    label=\"root\",       # fewer labels overall\n",
    "    fontsize=8,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_title(\"Pruned Regression Tree\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "fig.savefig(FIG_DIR / \"q1c_pruned_tree.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da288a",
   "metadata": {},
   "source": [
    "### **(d)** Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2618dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dabe9af",
   "metadata": {},
   "source": [
    "### **(e)** Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec5512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b88c0cc9",
   "metadata": {},
   "source": [
    "### **(f)** Method Comparison and Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd49529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87c1e906",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12344e1a",
   "metadata": {},
   "source": [
    "## **Question 2:** Business School Admissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3672da2",
   "metadata": {},
   "source": [
    "Consider the business school admission data available in the `admission.csv`. The admission officer of a business school has used an “index” of undergraduate grade point average (GPA, \\(X_1\\)) and graduate management aptitude test (GMAT, \\(X_2\\)) scores to help decide which applicants should be admitted to the school’s graduate programs. This index is used to categorize each applicant into one of three groups – admit (group 1), do not admit (group 2), and borderline (group 3).\n",
    "\n",
    "We will take the last four observations in each category as test data and the remaining observations as training data.\n",
    "\n",
    "- **Part (a):** Perform an exploratory analysis of the training data by examining appropriate plots and comment on how helpful these predictors may be in predicting response.  \n",
    "\n",
    "- **Part (b):** Perform an LDA using the training data. Superimpose the decision boundary on an appropriate display of the data. Does the decision boundary seem sensible? In addition, compute the confusion matrix and overall misclassification rate based on both training\n",
    "and test data. What do you observe?  \n",
    "\n",
    "- **Part (c):** Repeat (b) using QDA. \n",
    "\n",
    "- **Part (d):** Fit a KNN with \\(K\\) chosen optimally using test error rate. Report error rate, sensitivity, specificity, and AUC for the optimal KNN based on the training data. Also, report its estimated test error rate.  \n",
    "\n",
    "- **Part (e):** Compare the results in (b), (c) and (d). Which classifier would you recommend? Justify your conclusions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffd799f",
   "metadata": {},
   "source": [
    "### Q2-Specific Helper Functions and Shared Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de31fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function for scatter plots\n",
    "def plot_q2_scatter(df, ax, order, labels, colors, title=None, alpha=0.7):\n",
    "    \"\"\"Scatter plot of GPA vs GMAT colored by admission group.\"\"\"\n",
    "    for g in order:\n",
    "        subset = df[df[\"Group\"] == g]\n",
    "        ax.scatter(\n",
    "            subset[\"GPA\"],\n",
    "            subset[\"GMAT\"],\n",
    "            label=labels[g],\n",
    "            color=colors[g],\n",
    "            alpha=alpha,\n",
    "            edgecolor=\"k\",\n",
    "            s=60,\n",
    "        )\n",
    "    ax.set_xlabel(\"Undergraduate GPA\", fontsize=12, labelpad=10)\n",
    "    ax.set_ylabel(\"GMAT Score\", fontsize=12, labelpad=10)\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=14, fontweight=\"bold\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "# Mesh for plotting\n",
    "def build_gpa_gmat_mesh(df, *, gpa_pad=0.05, gmat_pad=10, n=300):\n",
    "    gpa_min, gpa_max = df[\"GPA\"].min() - gpa_pad, df[\"GPA\"].max() + gpa_pad\n",
    "    gmat_min, gmat_max = df[\"GMAT\"].min() - gmat_pad, df[\"GMAT\"].max() + gmat_pad\n",
    "\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(gpa_min, gpa_max, n),\n",
    "        np.linspace(gmat_min, gmat_max, n),\n",
    "    )\n",
    "\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    return xx, yy, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f835ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color/label mapping for groups\n",
    "q2_labels = {1: \"Admit\", 2: \"Not Admit\", 3: \"Border\"}\n",
    "q2_colors = {1: \"tab:blue\", 2: \"tab:orange\", 3: \"tab:green\"}\n",
    "q2_order = [2, 3, 1]\n",
    "\n",
    "# Names in order: Not Admit, Border, Admit\n",
    "q2_group_names = [q2_labels[g] for g in q2_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0a567f",
   "metadata": {},
   "source": [
    "### Data Load, Initial Inspection, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "q2_df = pd.read_csv(DATA_DIR / \"admission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982118c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial EDA summary\n",
    "de_levels = sorted(q2_df[\"De\"].astype(str).unique().tolist())\n",
    "group_levels = sorted(q2_df[\"Group\"].unique().tolist())\n",
    "\n",
    "class_counts = q2_df[\"Group\"].value_counts().sort_index()\n",
    "\n",
    "eda_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"item\": [\n",
    "            \"n_rows\",\n",
    "            \"n_cols\",\n",
    "            \"columns\",\n",
    "            \"De_levels\",\n",
    "            \"Group_levels\",\n",
    "            \"Group_counts\",\n",
    "        ],\n",
    "        \"value\": [\n",
    "            q2_df.shape[0],\n",
    "            q2_df.shape[1],\n",
    "            \", \".join(q2_df.columns.astype(str).tolist()),\n",
    "            \", \".join(de_levels),\n",
    "            \", \".join(map(str, group_levels)),\n",
    "            \"; \".join([f\"{k}:{v}\" for k, v in class_counts.items()]),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "# eda_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18584be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: Verify categorical labels match numeric group coding\n",
    "category_map = {\"admit\": 1, \"notadmit\": 2, \"border\": 3}\n",
    "\n",
    "categories_match = (q2_df[\"De\"].map(category_map) == q2_df[\"Group\"]).all()\n",
    "assert categories_match, \"Mismatch between De labels and Group codes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split:\n",
    "## Last 4 observations in each category -> test\n",
    "## Rest of observations -> train\n",
    "\n",
    "q2_test_idx = q2_df.groupby(\"Group\", sort=False).tail(4).index\n",
    "\n",
    "\n",
    "q2_train_df = q2_df.drop(index=q2_test_idx).copy()\n",
    "q2_test_df = q2_df.loc[q2_test_idx].copy()\n",
    "\n",
    "# Features/labels\n",
    "q2_X_train = q2_train_df[[\"GPA\", \"GMAT\"]].to_numpy()\n",
    "q2_y_train = q2_train_df[\"Group\"].to_numpy()\n",
    "\n",
    "q2_X_test = q2_test_df[[\"GPA\", \"GMAT\"]].to_numpy()\n",
    "q2_y_test = q2_test_df[\"Group\"].to_numpy()\n",
    "\n",
    "# Checks\n",
    "assert len(q2_test_df) == 12\n",
    "assert q2_train_df.shape[0] + q2_test_df.shape[0] == q2_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86a0455",
   "metadata": {},
   "source": [
    "### **2(a)** Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c820d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: GPA vs GMAT, colored by groups\n",
    "fig_scatter, ax_scatter = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "plot_q2_scatter(\n",
    "    df=q2_train_df,\n",
    "    ax=ax_scatter,\n",
    "    order=q2_order,\n",
    "    labels=q2_labels,\n",
    "    colors=q2_colors,\n",
    "    title=\"Training Data: GPA vs GMAT by Admission Group\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "fig_scatter.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "fig_scatter.savefig(FIG_DIR / \"q2_scatter_gpa_gmat.png\", bbox_inches=\"tight\")\n",
    "plt.close(fig_scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c72905",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_train_df_plot = q2_train_df.copy()\n",
    "q2_train_df_plot[\"GroupOrdered\"] = pd.Categorical(\n",
    "    q2_train_df_plot[\"Group\"].map(q2_labels),\n",
    "    categories=[q2_labels[g] for g in q2_order],\n",
    "    ordered=True,\n",
    ")\n",
    "\n",
    "fig_box, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Boxplot: GPA by Group\n",
    "q2_train_df_plot.boxplot(column=\"GPA\", by=\"GroupOrdered\", ax=axes[0], grid=False)\n",
    "axes[0].set_title(\"GPA by Admission Group\", fontsize=13)\n",
    "axes[0].set_xlabel(\"Group\", fontsize=12, labelpad=10)\n",
    "axes[0].set_ylabel(\"GPA\", fontsize=12, labelpad=10)\n",
    "\n",
    "# Boxplot: GMAT by Group\n",
    "q2_train_df_plot.boxplot(column=\"GMAT\", by=\"GroupOrdered\", ax=axes[1], grid=False)\n",
    "axes[1].set_title(\"GMAT by Admission Group\", fontsize=13)\n",
    "axes[1].set_xlabel(\"Group\", fontsize=12, labelpad=10)\n",
    "axes[1].set_ylabel(\"GMAT Score\", fontsize=12, labelpad=10)\n",
    "\n",
    "fig_box.suptitle(\n",
    "    \"Training Data: Marginal Distributions by Group\", fontsize=16, fontweight=\"bold\"\n",
    ")\n",
    "fig_box.tight_layout()\n",
    "\n",
    "\n",
    "# Save figure\n",
    "fig_box.savefig(FIG_DIR / \"q2_boxplots_gpa_gmat.png\", bbox_inches=\"tight\")\n",
    "plt.close(fig_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad85d72",
   "metadata": {},
   "source": [
    "### **2(b)** Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LDA on training data\n",
    "q2_lda = LinearDiscriminantAnalysis()\n",
    "q2_lda.fit(q2_X_train, q2_y_train)\n",
    "\n",
    "# Predictions\n",
    "q2_lda_train_pred = q2_lda.predict(q2_X_train)\n",
    "q2_lda_test_pred = q2_lda.predict(q2_X_test)\n",
    "\n",
    "# Sanity checks\n",
    "assert len(q2_lda_train_pred) == len(q2_y_train)\n",
    "assert len(q2_lda_test_pred) == len(q2_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ce27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a mesh over predictor space\n",
    "xx, yy, grid = build_gpa_gmat_mesh(q2_train_df)\n",
    "Z = q2_lda.predict(grid).reshape(xx.shape)\n",
    "\n",
    "# Plot decision regions + training points\n",
    "fig_lda, ax_lda = plt.subplots(figsize=(6.5, 5.5))\n",
    "\n",
    "# Decision regions\n",
    "ax_lda.contourf(xx, yy, Z, alpha=0.18)\n",
    "\n",
    "# Decision boundaries\n",
    "ax_lda.contour(xx, yy, Z, levels=[1.5, 2.5], colors=\"k\", linewidths=1)\n",
    "\n",
    "plot_q2_scatter(\n",
    "    df=q2_train_df,\n",
    "    ax=ax_lda,\n",
    "    order=q2_order,\n",
    "    labels=q2_labels,\n",
    "    colors=q2_colors,\n",
    "    title=\"LDA Decision Regions (Training Data)\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "fig_lda.tight_layout()\n",
    "\n",
    "# Save plot artifact\n",
    "fig_lda.savefig(FIG_DIR / \"q2_lda_boundary.png\", bbox_inches=\"tight\")\n",
    "plt.close(fig_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5332cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "# Rows = true class, Columns = predicted class\n",
    "# Order: Not Admit (2), Border (3), Admit (1)\n",
    "q2_lda_cm_train = confusion_matrix(q2_y_train, q2_lda_train_pred, labels=q2_order)\n",
    "\n",
    "q2_lda_cm_test = confusion_matrix(q2_y_test, q2_lda_test_pred, labels=q2_order)\n",
    "\n",
    "# Overall misclassification rates\n",
    "q2_lda_train_err = 1.0 - np.mean(q2_lda_train_pred == q2_y_train)\n",
    "q2_lda_test_err = 1.0 - np.mean(q2_lda_test_pred == q2_y_test)\n",
    "\n",
    "# Sanity checks\n",
    "assert q2_lda_cm_train.shape == (3, 3)\n",
    "assert q2_lda_cm_test.shape == (3, 3)\n",
    "assert 0.0 <= q2_lda_train_err <= 1.0\n",
    "assert 0.0 <= q2_lda_test_err <= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253053aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices as labeled DataFrames\n",
    "q2_lda_cm_train_df = pd.DataFrame(\n",
    "    q2_lda_cm_train, index=q2_group_names, columns=q2_group_names\n",
    ")\n",
    "q2_lda_cm_test_df = pd.DataFrame(\n",
    "    q2_lda_cm_test, index=q2_group_names, columns=q2_group_names\n",
    ")\n",
    "\n",
    "# Error-rate summary\n",
    "q2_lda_metrics_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Misclassification Rate\": [q2_lda_train_err, q2_lda_test_err],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create LaTex tables\n",
    "q2_lda_all_tables_tex = \"\\n\".join(\n",
    "    [\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_lda_cm_train_df, index=True, float_fmt=None),\n",
    "            caption=\"LDA confusion matrix (training data). Rows are true classes and columns are predicted classes.\",\n",
    "            label=\"tab:q2_lda_cm_train\",\n",
    "        ),\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_lda_cm_test_df, index=True, float_fmt=None),\n",
    "            caption=\"LDA confusion matrix (test data). Rows are true classes and columns are predicted classes.\",\n",
    "            label=\"tab:q2_lda_cm_test\",\n",
    "        ),\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_lda_metrics_df, index=False, float_fmt=\"%.4f\"),\n",
    "            caption=\"LDA overall misclassification rates.\",\n",
    "            label=\"tab:q2_lda_error_rates\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Write output\n",
    "(TAB_DIR / \"q2_lda_tables.tex\").write_text(q2_lda_all_tables_tex, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429e5efe",
   "metadata": {},
   "source": [
    "\n",
    "### **2(c)** Quadratic Discriminant Analysis (QDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928fb507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit QDA on training data\n",
    "q2_qda = QuadraticDiscriminantAnalysis()\n",
    "q2_qda.fit(q2_X_train, q2_y_train)\n",
    "\n",
    "# Predictions\n",
    "q2_qda_train_pred = q2_qda.predict(q2_X_train)\n",
    "q2_qda_test_pred = q2_qda.predict(q2_X_test)\n",
    "\n",
    "# Sanity checks\n",
    "assert len(q2_qda_train_pred) == len(q2_y_train)\n",
    "assert len(q2_qda_test_pred) == len(q2_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build mesh over predictor space\n",
    "xx, yy, grid = build_gpa_gmat_mesh(q2_train_df)\n",
    "Z = q2_qda.predict(grid).reshape(xx.shape)\n",
    "\n",
    "# Plot decision regions + training points\n",
    "fig_qda, ax_qda = plt.subplots(figsize=(6.5, 5.5))\n",
    "\n",
    "# Decision regions\n",
    "ax_qda.contourf(xx, yy, Z, alpha=0.18)\n",
    "\n",
    "# Decision boundaries\n",
    "ax_qda.contour(xx, yy, Z, levels=[1.5, 2.5], colors=\"k\", linewidths=1)\n",
    "\n",
    "plot_q2_scatter(\n",
    "    df=q2_train_df,\n",
    "    ax=ax_qda,\n",
    "    order=q2_order,\n",
    "    labels=q2_labels,\n",
    "    colors=q2_colors,\n",
    "    title=\"QDA Decision Regions (Training Data)\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "fig_qda.tight_layout()\n",
    "fig_qda.savefig(FIG_DIR / \"q2_qda_boundary.png\", bbox_inches=\"tight\")\n",
    "plt.close(fig_qda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2503daf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "# Rows = true class, Columns = predicted class\n",
    "# Order: Not Admit (2), Border (3), Admit (1)\n",
    "q2_qda_cm_train = confusion_matrix(q2_y_train, q2_qda_train_pred, labels=q2_order)\n",
    "\n",
    "q2_qda_cm_test = confusion_matrix(q2_y_test, q2_qda_test_pred, labels=q2_order)\n",
    "\n",
    "# Misclassification rates\n",
    "q2_qda_train_err = 1.0 - np.mean(q2_qda_train_pred == q2_y_train)\n",
    "q2_qda_test_err = 1.0 - np.mean(q2_qda_test_pred == q2_y_test)\n",
    "\n",
    "# Sanity checks\n",
    "assert q2_qda_cm_train.shape == (3, 3)\n",
    "assert q2_qda_cm_test.shape == (3, 3)\n",
    "assert 0.0 <= q2_qda_train_err <= 1.0\n",
    "assert 0.0 <= q2_qda_test_err <= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices as labeled DataFrames\n",
    "q2_qda_cm_train_df = pd.DataFrame(\n",
    "    q2_qda_cm_train, index=q2_group_names, columns=q2_group_names\n",
    ")\n",
    "q2_qda_cm_test_df = pd.DataFrame(\n",
    "    q2_qda_cm_test, index=q2_group_names, columns=q2_group_names\n",
    ")\n",
    "\n",
    "# Error-rate summary\n",
    "q2_qda_metrics_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Misclassification Rate\": [q2_qda_train_err, q2_qda_test_err],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create LaTex tables\n",
    "qda_tables_tex = \"\\n\".join(\n",
    "    [\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_qda_cm_train_df, float_fmt=None),\n",
    "            caption=\"QDA confusion matrix (training data). Rows are true classes and columns are predicted classes.\",\n",
    "            label=\"tab:q2_qda_cm_train\",\n",
    "        ),\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_qda_cm_test_df, float_fmt=None),\n",
    "            caption=\"QDA confusion matrix (test data). Rows are true classes and columns are predicted classes.\",\n",
    "            label=\"tab:q2_qda_cm_test\",\n",
    "        ),\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_qda_metrics_df, index=False),\n",
    "            caption=\"QDA overall misclassification rates.\",\n",
    "            label=\"tab:q2_qda_error_rates\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Write output\n",
    "(TAB_DIR / \"q2_qda_tables.tex\").write_text(qda_tables_tex, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4901f473",
   "metadata": {},
   "source": [
    "### **2(d)** K-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246a715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose K by minimizing Test Misclassification Rate\n",
    "\n",
    "# Odd k to Reduce class tie frequencies\n",
    "q2_knn_K_values = list(range(1, 26, 2))\n",
    "q2_knn_test_errors = []\n",
    "\n",
    "for K in q2_knn_K_values:\n",
    "    # Use Pipeline to avoid scaling data leakage and scaling errors\n",
    "    q2_knn = Pipeline(\n",
    "        [(\"scalar\", StandardScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=K))]\n",
    "    )\n",
    "    q2_knn.fit(q2_X_train, q2_y_train)\n",
    "    q2_test_pred = q2_knn.predict(q2_X_test)\n",
    "\n",
    "    test_err = 1.0 - np.mean(q2_test_pred == q2_y_test)\n",
    "    q2_knn_test_errors.append(test_err)\n",
    "\n",
    "q2_knn_results_df = pd.DataFrame(\n",
    "    {\"K\": q2_knn_K_values, \"test_error_rate\": q2_knn_test_errors}\n",
    ")\n",
    "\n",
    "# Optimal K (on test error ties, use smallest K)\n",
    "q2_knn_results_sorted = q2_knn_results_df.sort_values(\n",
    "    [\"test_error_rate\", \"K\"], ascending=[True, True]\n",
    ")\n",
    "\n",
    "q2_knn_best_row = q2_knn_results_sorted.iloc[0]\n",
    "\n",
    "q2_knn_K_star = int(q2_knn_best_row[\"K\"])\n",
    "q2_knn_test_err_star = float(q2_knn_best_row[\"test_error_rate\"])\n",
    "\n",
    "# Sanity Checks\n",
    "assert q2_knn_K_star in q2_knn_K_values\n",
    "assert 0.0 <= q2_knn_test_err_star <= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3912e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save K-sweep results to LaTex table\n",
    "q2_knn_results_sorted_rename = q2_knn_results_sorted.rename(\n",
    "    columns={\"test_error_rate\": \"Test Error Rate\"}\n",
    ")\n",
    "\n",
    "q2_knn_sweep_tex = wrap_table(\n",
    "    df_to_tabular_tex(q2_knn_results_sorted_rename, index=False),\n",
    "    caption=\"Sorted KNN test error rate (three-class) for candidate values of $K$.\",\n",
    "    label=\"tab:q2_knn_k_sweep\",\n",
    ")\n",
    "\n",
    "(TAB_DIR / \"q2_knn_k_sweep.tex\").write_text(q2_knn_sweep_tex, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0716ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit K* model on full 3-class training data\n",
    "q2_knn_star = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"knn\", KNeighborsClassifier(n_neighbors=q2_knn_K_star)),\n",
    "    ]\n",
    ")\n",
    "q2_knn_star.fit(q2_X_train, q2_y_train)\n",
    "\n",
    "# 3-class predictions\n",
    "q2_knn_train_pred3 = q2_knn_star.predict(q2_X_train)\n",
    "q2_knn_test_pred3 = q2_knn_star.predict(q2_X_test)\n",
    "\n",
    "# 3-class confusion matrices (ordered as Not Admit, Border, Admit)\n",
    "q2_knn_cm_train3 = confusion_matrix(q2_y_train, q2_knn_train_pred3, labels=q2_order)\n",
    "q2_knn_cm_test3 = confusion_matrix(q2_y_test, q2_knn_test_pred3, labels=q2_order)\n",
    "\n",
    "# 3-class misclassification rates\n",
    "q2_knn_train_err3 = 1.0 - np.mean(q2_knn_train_pred3 == q2_y_train)\n",
    "q2_knn_test_err3 = 1.0 - np.mean(q2_knn_test_pred3 == q2_y_test)\n",
    "\n",
    "# Sanity Checks\n",
    "assert q2_knn_cm_train3.shape == (3, 3)\n",
    "assert q2_knn_cm_test3.shape == (3, 3)\n",
    "assert 0.0 <= q2_knn_train_err3 <= 1.0\n",
    "assert 0.0 <= q2_knn_test_err3 <= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices as labeled DataFrames\n",
    "q2_knn_cm_train3_df = pd.DataFrame(\n",
    "    q2_knn_cm_train3, index=q2_group_names, columns=q2_group_names\n",
    ")\n",
    "q2_knn_cm_test3_df = pd.DataFrame(\n",
    "    q2_knn_cm_test3, index=q2_group_names, columns=q2_group_names\n",
    ")\n",
    "\n",
    "# Error-rate summary\n",
    "q2_knn_err3_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Dataset\": [\"Training\", \"Test\"],\n",
    "        \"Misclassification Rate\": [q2_knn_train_err3, q2_knn_test_err3],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create LaTex tables\n",
    "q2_knn_tables3_tex = \"\\n\".join(\n",
    "    [\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_knn_cm_train3_df, float_fmt=None),\n",
    "            caption=\"KNN confusion matrix at $K^*$ (training data). Rows are true classes and columns are predicted classes.\",\n",
    "            label=\"tab:q2_knn_cm_train3\",\n",
    "        ),\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_knn_cm_test3_df, float_fmt=None),\n",
    "            caption=\"KNN confusion matrix at $K^*$ (test data). Rows are true classes and columns are predicted classes.\",\n",
    "            label=\"tab:q2_knn_cm_test3\",\n",
    "        ),\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_knn_err3_df, index=False),\n",
    "            caption=\"KNN misclassification rates (three-class) at $K^*$.\",\n",
    "            label=\"tab:q2_knn_err3\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Write output\n",
    "(TAB_DIR / \"q2_knn_3class_tables.tex\").write_text(q2_knn_tables3_tex, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c301d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass OvR metrics on training data for KNN at K*\n",
    "\n",
    "# Confusion Matrix Totals\n",
    "n = q2_knn_cm_train3.sum()\n",
    "rowsum = q2_knn_cm_train3.sum(axis=1)  # actual totals per class\n",
    "colsum = q2_knn_cm_train3.sum(axis=0)  # predicted totals per class\n",
    "diag = np.diag(q2_knn_cm_train3)\n",
    "\n",
    "# OvR per-class sensitivity and specificity\n",
    "sens = diag / rowsum\n",
    "spec = (n - rowsum - colsum + diag) / (n - rowsum)\n",
    "\n",
    "# Macro averages\n",
    "sens_macro = sens.mean()\n",
    "spec_macro = spec.mean()\n",
    "\n",
    "# Multiclass AUC (OvR macro) using predicted probabilities\n",
    "proba_train = q2_knn_star.predict_proba(q2_X_train)\n",
    "\n",
    "# Align columns to labels [1,2,3] for `roc_auc_score()`\n",
    "proba_df = pd.DataFrame(proba_train, columns=q2_knn_star.named_steps[\"knn\"].classes_)\n",
    "proba_aligned = proba_df[[1, 2, 3]].to_numpy()\n",
    "\n",
    "q2_knn_auc_ovr_macro = roc_auc_score(\n",
    "    q2_y_train, proba_aligned, multi_class=\"ovr\", average=\"macro\"\n",
    ")\n",
    "\n",
    "# Package for table\n",
    "q2_knn_multiclass_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Class\": q2_group_names,\n",
    "        \"Sensitivity (OvR)\": sens,\n",
    "        \"Specificity (OvR)\": spec,\n",
    "    }\n",
    ")\n",
    "\n",
    "q2_knn_multiclass_summary_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Metric\": [\"Macro sensitivity\", \"Macro specificity\", \"AUC (OvR macro)\"],\n",
    "        \"Value\": [sens_macro, spec_macro, q2_knn_auc_ovr_macro],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Sanity checks\n",
    "assert q2_knn_multiclass_df.shape == (3, 3)\n",
    "assert 0.0 <= sens_macro <= 1.0\n",
    "assert 0.0 <= spec_macro <= 1.0\n",
    "assert 0.0 <= q2_knn_auc_ovr_macro <= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e2bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_knn_multiclass_tex = \"\\n\".join(\n",
    "    [\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(q2_knn_multiclass_df, float_fmt=\"%.4f\", index=False),\n",
    "            caption=\"KNN multiclass one-vs-rest (OvR) sensitivity and specificity by class (training data) at $K^*$.\",\n",
    "            label=\"tab:q2_knn_ovr_by_class\",\n",
    "        ),\n",
    "        wrap_table(\n",
    "            df_to_tabular_tex(\n",
    "                q2_knn_multiclass_summary_df, float_fmt=\"%.4f\", index=False\n",
    "            ),\n",
    "            caption=\"KNN multiclass OvR macro-averaged metrics (training data) at $K^*$.\",\n",
    "            label=\"tab:q2_knn_ovr_summary\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "(TAB_DIR / \"q2_knn_multiclass_metrics.tex\").write_text(\n",
    "    q2_knn_multiclass_tex, encoding=\"utf-8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8447ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final KNN summary table\n",
    "\n",
    "q2_knn_summary_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Quantity\": [\n",
    "            r\"$K^*$\",\n",
    "            \"Training error rate\",\n",
    "            \"Training sensitivity (OvR, macro)\",\n",
    "            \"Training specificity (OvR, macro)\",\n",
    "            \"Training AUC (OvR, macro)\",\n",
    "            \"Test error rate\",\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            q2_knn_K_star,\n",
    "            q2_knn_train_err3,\n",
    "            sens_macro,\n",
    "            spec_macro,\n",
    "            q2_knn_auc_ovr_macro,\n",
    "            q2_knn_test_err3,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "q2_knn_summary_tex = wrap_table(\n",
    "    df_to_tabular_tex(q2_knn_summary_df, float_fmt=\"%.4f\", index=False),\n",
    "    caption=\"Summary of optimal KNN performance.\",\n",
    "    label=\"tab:q2_knn_summary\",\n",
    ")\n",
    "\n",
    "(TAB_DIR / \"q2_knn_summary.tex\").write_text(q2_knn_summary_tex, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f2a510",
   "metadata": {},
   "source": [
    "### **2(e)** Method Comparison and Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb077798",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_model_comparison_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\"LDA\", \"QDA\", \"KNN (K=3)\"],\n",
    "        \"Training Error Rate\": [\n",
    "            q2_lda_train_err,\n",
    "            q2_qda_train_err,\n",
    "            q2_knn_train_err3,\n",
    "        ],\n",
    "        \"Test Error Rate\": [\n",
    "            q2_lda_test_err,\n",
    "            q2_qda_test_err,\n",
    "            q2_knn_test_err3,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "q2_model_comparison_tex = wrap_table(\n",
    "    df_to_tabular_tex(q2_model_comparison_df, index=False),\n",
    "    caption=\"Comparison of training and test misclassification rates for LDA, QDA, and KNN.\",\n",
    "    label=\"tab:q2_model_comparison\",\n",
    ")\n",
    "\n",
    "(TAB_DIR / \"q2_model_comparison.tex\").write_text(\n",
    "    q2_model_comparison_tex, encoding=\"utf-8\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
